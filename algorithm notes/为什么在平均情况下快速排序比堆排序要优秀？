1.堆排比较的几乎都不是相邻元素，对cache极不友好，这才是很少被采用的原因。
数学上的时间复杂度不代表实际运行时的情况。


2.简单来说，就是局部性原理。
在堆排中，每一个操作都是不利于程序的局部性原理的，
每次元素间的比较、数的调整等，都不是相邻或者尽可能附近的元素间的比较
(堆调整每次都从堆底拿元素到堆顶然后向下进行调整），
那么这就需要不断地在磁盘和内存间换入换出数据。

反观快排，利用分而治之的方法，元素间的比较都在某个段内，局部性相当好。


3.堆底的元素肯定很小，将它拿到堆顶和原本属于最大元素的两个子节点比较，
它比它们大的可能性是微乎其微的。实际上它肯定小于其中的一个儿子。而大于另一个儿子的可能性非常小。
于是，这一次比较的结果就是概率不均等的，根据前面的分析，概率不均等的比较是不明智的，
因为它并不能保证在糟糕情况下也能将问题的可能性削减到原本的1/2。
可以想像一种极端情况，如果a肯定小于b，
那么比较a和b就会什么信息也得不到——原本剩下多少可能性还是剩下多少可能性。

在堆排里面有大量这种近乎无效的比较，因为被拿到堆顶的那个元素几乎肯定是很小的，
而靠近堆顶的元素又几乎肯定是很大的，将一个很小的数和一个很大的数比较，结果几乎肯定是“小于”的，
这就意味着问题的可能性只被排除掉了很小一部分。

这就是为什么堆排比较慢（堆排虽然和快排一样复杂度都是O(NlogN)但堆排复杂度的常系数更大）。
