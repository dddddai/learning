1.堆排比较的几乎都不是相邻元素，对cache极不友好，这才是很少被采用的原因。
数学上的时间复杂度不代表实际运行时的情况。

一句话就是：因为堆排序下，数据读取的开销变大。

在计算机进行运算的时候，数据不一定会从内存读取出来，而是从一种叫cache的存储单位读取。
原因是cache相比内存，读取速度非常快，所以cache会把一部分我们经常读取的数据暂时储存起来，
以便下一次读取的时候，可以不必跑到内存去读，而是直接在cache里面找。
一般认为读取数据遵从两个原则：temporal locality，也就是不久前读取过的一个数据，
在之后很可能还会被读取一遍；另一个叫spatial locality，
也就是说读取一个数据，在它周围内存地址存储的数据也很有可能被读取到。
因此，在读取一个单位的数据(比如1个word)之后，不光单个word会被存入cache，
与之内存地址相邻的几个word，都会以一个block为单位存入cache中。
另外，cache相比内存小得多，当cache满了之后，会将旧的数据剔除，将新的数据覆盖上去。
在进行堆排序的过程中，由于我们要比较一个数组前一半和后一半的数字的大小，
而当数组比较长的时候，这前一半和后一半的数据相隔比较远，
这就导致了经常在cache里面找不到要读取的数据，需要从内存中读出来，
而当cache满了之后，以前读取的数据又要被剔除。

简而言之快排和堆排读取arr[i]这个元素的平均时间是不一样的。


2.简单来说，就是局部性原理。
在堆排中，每一个操作都是不利于程序的局部性原理的，
每次元素间的比较、数的调整等，都不是相邻或者尽可能附近的元素间的比较
(堆调整每次都从堆底拿元素到堆顶然后向下进行调整），
那么这就需要不断地在磁盘和内存间换入换出数据。

反观快排，利用分而治之的方法，元素间的比较都在某个段内，局部性相当好。


3.堆底的元素肯定很小，将它拿到堆顶和原本属于最大元素的两个子节点比较，
它比它们大的可能性是微乎其微的。实际上它肯定小于其中的一个儿子。而大于另一个儿子的可能性非常小。
于是，这一次比较的结果就是概率不均等的，根据前面的分析，概率不均等的比较是不明智的，
因为它并不能保证在糟糕情况下也能将问题的可能性削减到原本的1/2。
可以想像一种极端情况，如果a肯定小于b，
那么比较a和b就会什么信息也得不到——原本剩下多少可能性还是剩下多少可能性。

在堆排里面有大量这种近乎无效的比较，因为被拿到堆顶的那个元素几乎肯定是很小的，
而靠近堆顶的元素又几乎肯定是很大的，将一个很小的数和一个很大的数比较，结果几乎肯定是“小于”的，
这就意味着问题的可能性只被排除掉了很小一部分。

这就是为什么堆排比较慢（堆排虽然和快排一样复杂度都是O(NlogN)但堆排复杂度的常系数更大）。
